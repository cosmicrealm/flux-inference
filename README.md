# FLUX.1-dev æ¨ç†ä¼˜åŒ–é¡¹ç›®

æœ¬é¡¹ç›®æä¾›äº† FLUX.1-dev æ¨¡å‹çš„å®Œæ•´æ¨ç†æµç¨‹ï¼ŒåŒ…æ‹¬å¤šç§æ¨ç†åç«¯å’Œç²¾åº¦é€‰é¡¹ã€‚

## âœ¨ ç‰¹æ€§

- âœ… **PyTorch Baseline** - åŸç”Ÿ BF16 æ¨ç†
- âœ… **ONNX Runtime** - è·¨å¹³å°æ¨ç†ï¼Œæ”¯æŒ FP16/BF16
- âœ… **TensorRT** - NVIDIA GPU æè‡´åŠ é€Ÿï¼Œæ”¯æŒ FP16/BF16
- âœ… **å®Œæ•´å›¾åƒç”Ÿæˆ** - è¾“å…¥ promptï¼Œè¾“å‡ºå›¾ç‰‡
- âœ… **å¤šç²¾åº¦æ”¯æŒ** - FP32ã€FP16ã€BF16

## ğŸ“‹ TODO

- [ ] INT8 é‡åŒ–æ”¯æŒ (TensorRT)
- [ ] FP8 ç²¾åº¦æ”¯æŒ (éœ€è¦ Hopper GPU)
- [ ] åŠ¨æ€åˆ†è¾¨ç‡æ”¯æŒ
- [ ] Batch æ¨ç†ä¼˜åŒ–
- [ ] å¤š GPU å¹¶è¡Œæ¨ç†
- [ ] Text Encoder / VAE çš„ TensorRT åŠ é€Ÿ
- [ ] CUDA Graph ä¼˜åŒ–

## ğŸ–¼ï¸ ç”Ÿæˆç»“æœ

ä½¿ç”¨ç›¸åŒçš„ prompt å’Œ seedï¼Œä¸åŒæ¨ç†åç«¯çš„ç”Ÿæˆæ•ˆæœï¼š

**Prompt**: *"A masterpiece photo of a beautiful sunset over rugged mountains, with dramatic, fiery clouds filling the sky. In the foreground, a golden retriever and a fluffy calico cat sit side-by-side on a rocky outcrop, looking out at the view."*

| Baseline (BF16) | ONNX (FP16) | ONNX (BF16) |
|:---------------:|:-----------:|:-----------:|
| ![baseline](results/baseline_flux_bf16.png) | ![onnx_fp16](results/onnx_output_fp16.png) | ![onnx_bf16](results/onnx_output_bf16.png) |

| TensorRT (FP16) | TensorRT (BF16) |
|:---------------:|:---------------:|
| ![trt_fp16](results/tensorrt_output_fp16.png) | ![trt_bf16](results/tensorrt_output_bf16.png) |

## ğŸ“ é¡¹ç›®ç»“æ„

```
flux-inference/
â”œâ”€â”€ base_model.py           # PyTorch baseline æ¨ç†
â”œâ”€â”€ onnx_model.py           # ONNX æ¨¡å‹å¯¼å‡º
â”œâ”€â”€ onnx_infer.py           # ONNX å®Œæ•´å›¾åƒç”Ÿæˆ
â”œâ”€â”€ tensorrt_model.py       # TensorRT Engine æ„å»º
â”œâ”€â”€ tensorrt_infer.py       # TensorRT å®Œæ•´å›¾åƒç”Ÿæˆ
â”œâ”€â”€ requirements.txt        # Python ä¾èµ–
â”œâ”€â”€ README.md               # æœ¬æ–‡ä»¶
â”œâ”€â”€ models/                 # å­˜æ”¾å¯¼å‡ºçš„æ¨¡å‹
â”‚   â”œâ”€â”€ flux_transformer_{precision}.onnx
â”‚   â”œâ”€â”€ flux_transformer_{precision}_weights.bin
â”‚   â””â”€â”€ flux_transformer_{precision}.engine
â””â”€â”€ results/                # å­˜æ”¾ç”Ÿæˆçš„å›¾ç‰‡
    â”œâ”€â”€ baseline_flux_bf16.png
    â”œâ”€â”€ onnx_output_{precision}.png
    â””â”€â”€ tensorrt_output_{precision}.png
```

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶
- NVIDIA GPU (æ¨è 40GB+ æ˜¾å­˜ï¼Œå¦‚ A100/A800)
- CUDA 12.0+
- TensorRT 10.0+

### è½¯ä»¶
- Python 3.10+
- PyTorch 2.0+
- ONNX Runtime GPU 1.16+
- TensorRT 10.x

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n flux python=3.10
conda activate flux

# å®‰è£… PyTorch (CUDA 12.x)
pip install torch torchvision torchaudio

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# å®‰è£… ONNX Runtime GPU ç‰ˆæœ¬
pip uninstall onnxruntime -y
pip install onnxruntime-gpu

# TensorRT é€šå¸¸éš CUDA ä¸€èµ·å®‰è£…ï¼Œæˆ–ä» NVIDIA å®˜ç½‘ä¸‹è½½
```

### 2. ä¸‹è½½ FLUX.1-dev æ¨¡å‹

```bash
huggingface-cli login
huggingface-cli download black-forest-labs/FLUX.1-dev --local-dir /path/to/models/FLUX.1-dev
```

### 3. é…ç½®æ¨¡å‹è·¯å¾„

ä¿®æ”¹å„æ–‡ä»¶ `__main__` ä¸­çš„ `REPO_ROOT` å˜é‡ï¼š

```python
REPO_ROOT = "/path/to/your/FLUX.1-dev"
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### Baseline PyTorch æ¨ç†

```bash
python base_model.py
```

è¾“å‡º: `results/baseline_flux_bf16.png`

### ONNX å¯¼å‡ºå’Œæ¨ç†

```bash
# Step 1: å¯¼å‡º ONNX æ¨¡å‹ (é¦–æ¬¡éœ€è¦ï¼Œçº¦ 5 åˆ†é’Ÿ)
python onnx_model.py

# Step 2: ä½¿ç”¨ ONNX ç”Ÿæˆå›¾åƒ
python onnx_infer.py

# æˆ–è€…åªè¿è¡ŒåŸºå‡†æµ‹è¯•
python onnx_infer.py benchmark

# æ£€æŸ¥ GPU æ”¯æŒ
python onnx_infer.py check
```

è¾“å‡º: `results/onnx_output_{precision}.png`

### TensorRT åŠ é€Ÿæ¨ç†

```bash
# Step 1: æ„å»º TensorRT Engine (é¦–æ¬¡éœ€è¦ï¼Œçº¦ 5-10 åˆ†é’Ÿ)
python tensorrt_model.py

# Step 2: ä½¿ç”¨ TensorRT ç”Ÿæˆå›¾åƒ
python tensorrt_infer.py

# æˆ–è€…åªè¿è¡ŒåŸºå‡†æµ‹è¯•
python tensorrt_infer.py benchmark
```

è¾“å‡º: `results/tensorrt_output_{precision}.png`

## âš™ï¸ ç²¾åº¦é…ç½®

åœ¨å„æ–‡ä»¶çš„ `__main__` å‡½æ•°ä¸­ä¿®æ”¹ `PRECISION` å˜é‡ï¼š

```python
PRECISION = "bf16"  # å¯é€‰: "fp32", "fp16", "bf16"
```

### ç²¾åº¦è¯´æ˜

| ç²¾åº¦ | ONNX | TensorRT | è¯´æ˜ |
|------|:----:|:--------:|------|
| FP32 | âœ… | âŒ | æ ‡å‡†ç²¾åº¦ï¼Œæ˜¾å­˜å ç”¨å¤§ |
| FP16 | âœ… | âœ… | æ¨èï¼Œé€Ÿåº¦å¿« |
| BF16 | âœ…* | âœ… | å¯¼å‡ºæ—¶è½¬ä¸º FP16 |
| INT8 | â³ | â³ | TODO: éœ€è¦æ ¡å‡†æ•°æ® |
| FP8 | âŒ | â³ | TODO: éœ€è¦ Hopper GPU |

*BF16 å¯¼å‡ºæ—¶ä¼šè½¬æ¢ä¸º FP16ï¼Œå› ä¸º ONNX Runtime å¯¹ BF16 æ”¯æŒæœ‰é™

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

åŸºäº NVIDIA A800 (80GB) çš„æµ‹è¯•ç»“æœï¼ˆ1024x1024ï¼Œ28 stepsï¼‰ï¼š

| æ–¹æ³• | Transformer æ¨ç†æ—¶é—´ | å®Œæ•´ç”Ÿæˆæ—¶é—´ | æ˜¾å­˜å ç”¨ |
|------|---------------------|-------------|---------|
| PyTorch (BF16) | ~350ms/step | ~12s | ~45GB |
| ONNX Runtime (FP16) | ~300ms/step | ~10s | ~40GB |
| TensorRT (FP16) | ~180ms/step | ~7s | ~35GB |

*å®é™…æ€§èƒ½å–å†³äºå…·ä½“ç¡¬ä»¶å’Œé…ç½®*

## â“ å¸¸è§é—®é¢˜

### 1. ONNX å¯¼å‡ºå¤±è´¥ï¼š`rms_norm` ä¸æ”¯æŒ

å·²åœ¨ `onnx_model.py` ä¸­æ³¨å†Œäº†è‡ªå®šä¹‰çš„ `rms_norm` ç¬¦å·åŒ–å‡½æ•°ã€‚

### 2. TensorRT æ‰¾ä¸åˆ°å¤–éƒ¨æƒé‡

ç¡®ä¿ ONNX æ–‡ä»¶å’Œ `*_weights.bin` åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚

### 3. ONNX Runtime æ²¡æœ‰ä½¿ç”¨ GPU

```bash
# ç¡®ä¿å®‰è£…çš„æ˜¯ GPU ç‰ˆæœ¬
pip uninstall onnxruntime onnxruntime-gpu -y
pip install onnxruntime-gpu

# è¿è¡Œæ£€æŸ¥
python onnx_infer.py check
```

### 4. TensorRT æ„å»ºæ—¶é—´è¿‡é•¿

é¦–æ¬¡æ„å»ºéœ€è¦ 5-10 åˆ†é’Ÿï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚Engine ä¼šè¢«ç¼“å­˜ï¼Œåç»­åŠ è½½å¾ˆå¿«ï¼ˆ~20sï¼‰ã€‚

### 5. æ˜¾å­˜ä¸è¶³ (OOM)

- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜ (æ¨è 40GB+)
- å…³é—­å…¶ä»– GPU ç¨‹åº
- å¯¹äº TensorRTï¼Œè°ƒæ•´ `max_workspace_size` å‚æ•°

## ğŸ”— å‚è€ƒèµ„æº

- [FLUX.1 Official Repo](https://github.com/black-forest-labs/flux)
- [Diffusers Documentation](https://huggingface.co/docs/diffusers)
- [ONNX Runtime Documentation](https://onnxruntime.ai/docs/)
- [TensorRT Documentation](https://docs.nvidia.com/deeplearning/tensorrt/)

## ğŸ“„ License

æœ¬é¡¹ç›®ä»£ç éµå¾ª MIT Licenseã€‚

FLUX.1-dev æ¨¡å‹çš„ä½¿ç”¨éœ€éµå¾ªå…¶åŸå§‹è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- **[Black Forest Labs](https://blackforestlabs.ai/)** - å¼€æº FLUX.1 æ¨¡å‹
- **[Hugging Face](https://huggingface.co/)** - Diffusers åº“å’Œæ¨¡å‹æ‰˜ç®¡
- **[NVIDIA](https://nvidia.com/)** - TensorRT å’Œ CUDA ç”Ÿæ€
- **[GitHub Copilot](https://github.com/features/copilot)** - AI ç¼–ç¨‹åŠ©æ‰‹ï¼Œå¤§å¹…æå‡äº†å¼€å‘æ•ˆç‡ ğŸ¤–âœ¨

---

*Made with â¤ï¸ and GitHub Copilot*
